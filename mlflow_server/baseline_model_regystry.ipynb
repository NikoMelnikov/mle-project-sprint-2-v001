{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2 as psycopg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from autofeat import AutoFeatRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import mlflow\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"Baseline model registration\"\n",
    "RUN_NAME = \"Nick_projecr _run_1\"\n",
    "\n",
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.getenv(\"DB_DESTINATION_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.getenv(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.getenv(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "TABLE_NAME = \"flat_cleaned_churn\"\n",
    "\n",
    "with psycopg.connect(**connection) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "        data = cur.fetchall()\n",
    "        columns = [col[0] for col in cur.description]\n",
    "    \n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>build_id</th>\n",
       "      <th>build_year</th>\n",
       "      <th>building_type_int</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>ceiling_height</th>\n",
       "      <th>flats_count</th>\n",
       "      <th>floors_total</th>\n",
       "      <th>has_elevator</th>\n",
       "      <th>floor</th>\n",
       "      <th>kitchen_area</th>\n",
       "      <th>living_area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>is_apartment</th>\n",
       "      <th>studio</th>\n",
       "      <th>total_area</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16093</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>55.834713</td>\n",
       "      <td>37.448383</td>\n",
       "      <td>2.64</td>\n",
       "      <td>204</td>\n",
       "      <td>17</td>\n",
       "      <td>true</td>\n",
       "      <td>16</td>\n",
       "      <td>10.1</td>\n",
       "      <td>44.799999</td>\n",
       "      <td>3</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>73.800003</td>\n",
       "      <td>13390000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3104</td>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>55.701302</td>\n",
       "      <td>37.738918</td>\n",
       "      <td>2.80</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>false</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>5500000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  build_id build_year building_type_int   latitude  longitude   \n",
       "0   1     16093 1994-01-01                 4  55.834713  37.448383  \\\n",
       "1   2      3104 1960-01-01                 1  55.701302  37.738918   \n",
       "\n",
       "   ceiling_height  flats_count  floors_total has_elevator  floor   \n",
       "0            2.64          204            17         true     16  \\\n",
       "1            2.80           20             5        false      1   \n",
       "\n",
       "   kitchen_area  living_area  rooms is_apartment studio  total_area   \n",
       "0          10.1    44.799999      3        false  false   73.800003  \\\n",
       "1           6.0    16.500000      1        false  false   32.000000   \n",
       "\n",
       "       target  \n",
       "0  13390000.0  \n",
       "1   5500000.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df.columns.tolist()\n",
    "columns_text = \",\".join(columns_list) \n",
    "with open(\"columns.txt\", \"w\", encoding=\"utf-8\") as fio:\n",
    "    fio.write(columns_text)\n",
    "    \n",
    "df.to_csv(\"flat_cleaned_churn\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9188352. 11099136. 11835392. ...  9725952.  9669632. 13305856.]\n"
     ]
    }
   ],
   "source": [
    "# Исключение столбцов с меньше чем 2 уникальными значениями\n",
    "unique_counts = df.nunique()\n",
    "columns_to_drop = unique_counts[unique_counts < 2].index\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "X = df.drop('target', axis=1).copy()\n",
    "# Разделение данных на категориальные и числовые\n",
    "cat_features = X.select_dtypes(include='object')\n",
    "potential_binary_features = cat_features.nunique() == 2\n",
    "binary_cat_features = cat_features[potential_binary_features[potential_binary_features].index]\n",
    "other_cat_features = cat_features[potential_binary_features[~potential_binary_features].index]\n",
    "num_features = X.select_dtypes(['float','int'])\n",
    "date_features = X.select_dtypes(include='datetime64[ns]')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('binary', OneHotEncoder(drop='if_binary'), binary_cat_features.columns.tolist()),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), other_cat_features.columns.tolist()),\n",
    "        ('num', StandardScaler(), num_features.columns.tolist()),\n",
    "        ('date', StandardScaler(), date_features.columns.tolist())  # Обработка признаков даты    \n",
    "    ],\n",
    "    remainder='drop', verbose_feature_names_out=False\n",
    "    )\n",
    "\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)  \n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ]\n",
    "    )\n",
    "\n",
    "y = df['target'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "prediction = pipeline.predict(X_test)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "mean = y_test.mean() #среднее значение целевой переменной на тесте\n",
    "MAE = mean_absolute_error(y_test, prediction)\n",
    "MSE = mean_squared_error(y_test, prediction)\n",
    "R2 = r2_score(y_test, prediction)\n",
    "y_error = y_test - prediction\n",
    "y_error = y_test - prediction  # рассчитаем вектор ошибок\n",
    "y_error_abs = abs(y_error)  # рассчитаем вектор модуля ошибок\n",
    "perc_error_abs = y_error_abs / y_test  # рассчитаем вектор относительных ошибок\n",
    "mape = perc_error_abs.mean()  # рассчитаем MAPE\n",
    "metrics['Среднее значение целевой переменной'] = mean.round(2)\n",
    "metrics['Средний модуль ошибки '] = MAE.round(2)\n",
    "metrics['Средняя квадратичная ошибка'] = MSE.round(2)\n",
    "metrics['Коэффициент детерминации'] = R2.round(2) \n",
    "metrics['Средняя абсолютная ошибка в процентах '] = mape.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка переменных окружения для работы с хранилищем\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.yandexcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] =  os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "# Установка URI для tracking и registry\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-project-sprint-2-v001/.venv_mle-project-sprint-2-v001/lib/python3.10/site-packages/mlflow/models/signature.py:212: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  inputs = _infer_schema(model_input) if model_input is not None else None\n",
      "Successfully registered model 'baseline_model_nikolaimelnikov'.\n",
      "2024/05/06 12:34:49 INFO mlflow.tracking._model_registry.client: Waiting up to 6 seconds for model version to finish creation. Model name: baseline_model_nikolaimelnikov, version 1\n",
      "Created version '1' of model 'baseline_model_nikolaimelnikov'.\n"
     ]
    }
   ],
   "source": [
    "REGISTRY_MODEL_NAME = \"baseline_model_nikolaimelnikov\"\n",
    "\n",
    "pip_requirements = '../requirements.txt' # ваш код здесь\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)# ваш код здесь\n",
    "input_example = input_example = X_test[:10]# ваш код здесь\n",
    "metadata = {'model_type': 'monthly'}# ваш код здесь\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "model_path = \"mlflow_baseline_model\"\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    mlflow.sklearn.log_model(pipeline, model_path, pip_requirements=pip_requirements,\n",
    "                             input_example=input_example, metadata=metadata, signature=signature,\n",
    "                             registered_model_name=REGISTRY_MODEL_NAME, await_registration_for=6)\n",
    "\n",
    "    # Дополнительные логгирования метрик и артефактов\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.log_artifact(\"columns.txt\", artifact_path=\"dataframe\")\n",
    "    mlflow.log_artifact(\"flat_cleaned_churn\", artifact_path=\"dataframe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mle-project-sprint-2-v001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
